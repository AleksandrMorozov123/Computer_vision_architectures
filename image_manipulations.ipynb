{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":7209687,"datasetId":4171509,"databundleVersionId":7299152},{"sourceType":"modelInstanceVersion","sourceId":65676,"databundleVersionId":8850165,"modelInstanceId":54795},{"sourceType":"modelInstanceVersion","sourceId":6101,"databundleVersionId":7429364,"modelInstanceId":4644},{"sourceType":"modelInstanceVersion","sourceId":6106,"databundleVersionId":7429374,"modelInstanceId":4649}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/aleksandrmorozov123/image-manipulations?scriptVersionId=230923259\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-04-01T04:09:52.562638Z","iopub.execute_input":"2025-04-01T04:09:52.563311Z","iopub.status.idle":"2025-04-01T04:09:53.942007Z","shell.execute_reply.started":"2025-04-01T04:09:52.563261Z","shell.execute_reply":"2025-04-01T04:09:53.94058Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"**Deep fakes generations with PyTorch**","metadata":{}},{"cell_type":"code","source":"import os\nif not os.path.exists('Faceswap-Deepfake-Pytorch'):\n    !wget -q https://www.dropbox.com/s/5ji7jl7httso9ny/person_images.zip\n    !wget -q https://raw.githubusercontent.com/sizhky/deep-fake-util/main/random_warp.py\n    !unzip -q person_images.zip\n\n!pip install -q torch_snippets torch_summary\n\nfrom torch_snippets import *\nfrom random_warp import get_training_data\nimport cv2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T04:12:51.639684Z","iopub.execute_input":"2025-04-01T04:12:51.641093Z","iopub.status.idle":"2025-04-01T04:13:17.222869Z","shell.execute_reply.started":"2025-04-01T04:12:51.64104Z","shell.execute_reply":"2025-04-01T04:13:17.221494Z"}},"outputs":[{"name":"stdout","text":"[person_images.zip]\n  End-of-central-directory signature not found.  Either this file is not\n  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n  latter case the central directory and zipfile comment will be found on\n  the last disk(s) of this archive.\nunzip:  cannot find zipfile directory in one of person_images.zip or\n        person_images.zip.zip, and cannot find person_images.zip.ZIP, period.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"face_cascade = cv2.CascadeClassifier (cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T04:13:21.711259Z","iopub.execute_input":"2025-04-01T04:13:21.711901Z","iopub.status.idle":"2025-04-01T04:13:21.754573Z","shell.execute_reply.started":"2025-04-01T04:13:21.711861Z","shell.execute_reply":"2025-04-01T04:13:21.753427Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def crop_face (img):\n    gray = cv2.cvtColor (img, cv2.COLOR_BGR2GRAY)\n    faces = face_cascade.detectMultiScale (gray, 1.3, 5)\n    if (len(faces)>0):\n        for (x, y, w, h) in faces:\n            img2 = img[y: (y + h), x: (x + w), :]\n        img2 = cv2.resize (img2, (256, 256))\n        return img2, True\n    else:\n        return img, False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T04:13:24.311693Z","iopub.execute_input":"2025-04-01T04:13:24.312177Z","iopub.status.idle":"2025-04-01T04:13:24.319805Z","shell.execute_reply.started":"2025-04-01T04:13:24.312139Z","shell.execute_reply":"2025-04-01T04:13:24.318316Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"!mkdir cropped_faces_personA\n!mkdir cropped_faces_personB\n\ndef crop_images (folder):\n    images = Glob (folder + '/*.jpg')\n    for i in range (len (images)):\n        img = read (images[i], 1)\n        img2, face_detected = crop_face (img)\n        if (face_detected == False):\n            continue\n        else:\n            cv2.imwrite ('cropped_faces_' + folder + '/' + str(i) + '.jpg', cv2.cvtColor(img2, cv2.COLOR_RGB2BGR))\ncrop_images ('personA')\ncrop_images ('personB')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T04:13:27.147735Z","iopub.execute_input":"2025-04-01T04:13:27.148129Z","iopub.status.idle":"2025-04-01T04:13:29.562826Z","shell.execute_reply.started":"2025-04-01T04:13:27.148097Z","shell.execute_reply":"2025-04-01T04:13:29.561055Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class ImageDataset (Dataset):\n    def __init__ (self, items_A, items_B):\n        self.items_A = np.concatenate ([read (f, 1)[None] for f in items_A])/255.\n        self.items_B = np.concatenate ([read (f, 1)[None] for f in items_B])/255.\n        self.items_A += self.items_B.mean (axis = (0, 1, 2)) - self.items_A.mean (axis = (0, 1, 2))\n\n    def __len__ (self):\n        return min (len (self.items_A), len (self.items_B))\n    def __getitem__ (self, ix):\n        a, b = choose (self.items_A), choose (self.items_B)\n        return a, b\n\n    def collate_fn (self, batch):\n        imsA, imsB = list (zip(*batch))\n        imsA, targetA = get_training_data (imsA, len (imsA))\n        imsB, targetB = get_training_data (imsB, len (imsB))\n        imsA, imsB, targetA, targetB = [torch.Tensor(i).permute (0, 3, 1, 2).to(device) for i in [imsA, imsB, targetA, targetB]]\n\na = ImageDataset (Glob ('cropped_faces_personA'), Glob ('cropped_faces_personB'))\nx = DataLoader (a, batch_size = 32, collate_fn = a.collate_fn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T04:24:59.752311Z","iopub.execute_input":"2025-04-01T04:24:59.752825Z","iopub.status.idle":"2025-04-01T04:24:59.848481Z","shell.execute_reply.started":"2025-04-01T04:24:59.752784Z","shell.execute_reply":"2025-04-01T04:24:59.846894Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mImageDataset\u001b[39;00m (\u001b[43mDataset\u001b[49m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m (\u001b[38;5;28mself\u001b[39m, items_A, items_B):\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems_A \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate ([read (f, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m items_A])\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255.\u001b[39m\n","\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"],"ename":"NameError","evalue":"name 'Dataset' is not defined","output_type":"error"}],"execution_count":8}]}